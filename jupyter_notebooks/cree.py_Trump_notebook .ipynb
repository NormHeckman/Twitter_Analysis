{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d6921fff-02b6-0a6d-19bd-126a34ae32d7"
   },
   "source": [
    "The notebook builds a simple word cloud \n",
    "------------------------------------------------------------------------ \n",
    "This notebook is based on one created by Kate on Kaggle.com. See the original at: https://www.kaggle.com/katerynad/d/benhamner/clinton-trump-tweets/wordcloud\n",
    "This version has been modified to work with files exported by cree.py by Norm Heckman\n",
    "The exported .csv files have been placed in the jupyter input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "6375f13f-f864-bca4-4b0e-4085fea2c69c",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f2cc727-3a42-a665-f7bd-499ff667d819"
   },
   "source": [
    "Read the data and separate candidates into 2 different data frames\n",
    "------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1ff70d52-0bbd-d373-f6c1-4a6149cd2fa2"
   },
   "source": [
    "We need to exclude stop words\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "70daae0f-9208-5bd0-8290-7b277e4fdd0f",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"http\")\n",
    "stopwords.add(\"https\")\n",
    "stopwords.add(\"amp\")\n",
    "stopwords.add(\"CO\")\n",
    "stopwords.add(\"Trump\")\n",
    "stopwords.add(\"Trump2016\")\n",
    "stopwords.add(\"Donald\")\n",
    "stopwords.add(\"Clinton\")\n",
    "stopwords.add(\"Hillary\")\n",
    "stopwords.add(\"realDonaldTrump\")\n",
    "stopwords.add(\"will\")\n",
    "stopwords.add(\"say\")\n",
    "stopwords.add(\"said\")\n",
    "stopwords.add(\"let\")\n",
    "stopwords.add(\"vote\")\n",
    "stopwords.add(\"now\")\n",
    "stopwords.add(\"go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "153f7d74-831f-b16c-541b-3b05099fe4ee",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 134: expected 8 fields, saw 9\n",
      "Skipping line 137: expected 8 fields, saw 9\n",
      "Skipping line 458: expected 8 fields, saw 10\n",
      "Skipping line 493: expected 8 fields, saw 9\n",
      "Skipping line 495: expected 8 fields, saw 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('c:/workspace/jupyter/input/tweets.csv', error_bad_lines=False)\n",
    "\n",
    "# Had to add error skipping due to crappy input from cree.py - neh\n",
    "\n",
    "# For cree.py files -Column 'Username' holds twitter handle  and 'Context' contains the tweet string\n",
    "\n",
    "# This particular dataset only contains tweets from CLeandoswki_ and realDonaldTrump \n",
    "\n",
    "df_cl=df.loc[(df['Username']=='CLewandowski_'),['Context']]\n",
    "df_dt=df.loc[(df['Username']=='realDonaldTrump'),['Context']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "da7579df-97f3-93b4-1669-8dfd6fea6dda"
   },
   "source": [
    "Now lets build a word clouds\n",
    "---------------------------------------\n",
    "First for CLewandowski_ then for realDonaldTrump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "24d02f41-9884-25d2-9a68-460dcea298b4",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud_dt = WordCloud(max_font_size=40, relative_scaling=.5,stopwords=stopwords).generate(df_dt['Context'].str.cat())\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud_dt)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79475eea-854b-cdb7-ff8c-a17f04a9ef90",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud_cl = WordCloud(max_font_size=40, relative_scaling=.5,stopwords=stopwords).generate(df_cl['Context'].str.cat())\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud_cl)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 20,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
